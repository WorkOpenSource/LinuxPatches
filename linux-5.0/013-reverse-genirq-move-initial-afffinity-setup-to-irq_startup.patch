Reversing the following Linux commit to speed up the device

The following commit decreasis the packet transfer by 45% and increases
it by the same percentage when removing it from the kernel code.




commit 2e051552df69af6d134c2592d0d6f1ac80f01190
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Tue Jun 20 01:37:23 2017 +0200

    genirq: Move initial affinity setup to irq_startup()
    
    The startup vs. setaffinity ordering of interrupts depends on the
    IRQF_NOAUTOEN flag. Chained interrupts are not getting any affinity
    assignment at all.
    
    A regular interrupt is started up and then the affinity is set. A
    IRQF_NOAUTOEN marked interrupt is not started up, but the affinity is set
    nevertheless.
    
    Move the affinity setup to startup_irq() so the ordering is always the same
    and chained interrupts get the proper default affinity assigned as well.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Cc: Jens Axboe <axboe@kernel.dk>
    Cc: Marc Zyngier <marc.zyngier@arm.com>
    Cc: Michael Ellerman <mpe@ellerman.id.au>
    Cc: Keith Busch <keith.busch@intel.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Christoph Hellwig <hch@lst.de>
    Link: http://lkml.kernel.org/r/20170619235445.020534783@linutronix.de

diff --git a/kernel/irq/chip.c b/kernel/irq/chip.c
index a2b3d9de999c..f8263d90657f 100644
--- a/kernel/irq/chip.c
+++ b/kernel/irq/chip.c
@@ -266,10 +266,8 @@ int irq_startup(struct irq_desc *desc, bool resend, bool force)
 		switch (__irq_startup_managed(desc, aff, force)) {
 		case IRQ_STARTUP_NORMAL:
 			ret = __irq_startup(desc);
-			irq_setup_affinity(desc);
 			break;
 		case IRQ_STARTUP_MANAGED:
-			irq_do_set_affinity(d, aff, false);
 			ret = __irq_startup(desc);
 			break;
 		case IRQ_STARTUP_ABORT:
diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index 9dbdccab3b6a..96f3d6957ff2 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -1435,12 +1435,6 @@ __setup_irq(unsigned int irq, struct irq_desc *desc, struct irqaction *new)
 		if (new->flags & IRQF_ONESHOT)
 			desc->istate |= IRQS_ONESHOT;
 
-		/* Exclude IRQ from balancing if requested */
-		if (new->flags & IRQF_NOBALANCING) {
-			irq_settings_set_no_balancing(desc);
-			irqd_set(&desc->irq_data, IRQD_NO_BALANCING);
-		}
-
 		if (irq_settings_can_autoenable(desc)) {
 			irq_startup(desc, IRQ_RESEND, IRQ_START_COND);
 		} else {
@@ -1455,6 +1449,15 @@ __setup_irq(unsigned int irq, struct irq_desc *desc, struct irqaction *new)
 			desc->depth = 1;
 		}
 
+		/* Exclude IRQ from balancing if requested */
+		if (new->flags & IRQF_NOBALANCING) {
+			irq_settings_set_no_balancing(desc);
+			irqd_set(&desc->irq_data, IRQD_NO_BALANCING);
+		}
+
+		/* Set default affinity mask once everything is setup */
+		irq_setup_affinity(desc);
+
 	} else if (new->flags & IRQF_TRIGGER_MASK) {
 		unsigned int nmsk = new->flags & IRQF_TRIGGER_MASK;
 		unsigned int omsk = irqd_get_trigger_type(&desc->irq_data);
